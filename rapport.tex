\documentclass[12pt,a4paper]{article}

% Packages de base
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[french]{babel}
\usepackage{hyperref}

% Mathématiques
\usepackage{cancel}
\usepackage{amsthm,amsmath,amsfonts,amssymb,dsfont}
\usepackage{stmaryrd}

% Mise en forme
\usepackage[x11names]{xcolor}
\usepackage{multicol}
\usepackage{graphicx}
\usepackage{tcolorbox}

% Figures
\usepackage{wrapfig}
\usepackage{float}

% Géométrie et titres
\usepackage[margin=2.5cm]{geometry}
\usepackage{titlesec}
\usepackage{caption}
\usepackage{subcaption}

% Théorèmes
\theoremstyle{plain}
\newtheorem{Th}{Théorème}[section]
\newtheorem{Lem}[Th]{Lemme}
\newtheorem{Prop}[Th]{Proposition}
\newtheorem*{Prop*}{Proposition}
\newtheorem*{Cor}{Corollaire}

\theoremstyle{definition}
\newtheorem{Df}{Définition}[section]
\newtheorem*{Df*}{Définition}
\newtheorem{Ex}{Exemple}[section]
\newtheorem*{Ex*}{Exemple}

\theoremstyle{remark}
\newtheorem*{NB}{Remarque}
\newtheorem*{NBs}{Remarques}

\title{UAV-Assisted Federated Learning with Autoencoders for IoT Image Classification\\
\large Rapport détaillé}
\author{Louis MENNRATH \and Valentin DAVID}
\date{26 février 2026}

\begin{document}

\maketitle

\tableofcontents
\newpage

\section{Introduction et contexte de l'IoT}


L'IoT (internet des objets) est depuis quelques années de plus en plus présent et amène des défis dans beaucoup de domaines. Elle produit beaucoup de données, des données qui sont très hétérogènes et non-IID (non indépendantes et identiquement distribuées), ce qui amène à des défis importants en termes d'apprentissage automatique. Ces défis sont amplifiés par le volume important des données généré par l'IoT.  
Dans notre cas, chaque capteur peut observer des phénomènes différents selon son emplacement géographique, son environnement local ou ses conditions d'opération. Cette hétérogénéité rend difficile l'application des techniques d'apprentissage automatique traditionnelles qui supposent généralement une distribution uniforme des données.

De plus, les données collectées sont souvent \textbf{peu ou pas annotées}. Dans ce contexte, il est particulièrement difficile de labelliser les données récupérées, notamment à cause du volume important de données, de la difficulté d'accès aux données (capteurs en milieux difficiles) ou encore à cause du coût engendré. 

Enfin, les réseaux IoT fonctionnent sous des contraintes en termes de ressources :

\begin{itemize}
    \item \textbf{Énergie} : Les capteurs, notamment ceux présents dans un environnement difficile, sont compliqués à alimenter (nécessité de batterie, panneaux solaires...)
    \item \textbf{Bande passante} : La transmission d'un volume important de données peut être difficile si le réseau propose un débit en bande passante limité. De plus, cela consomme de l'énergie pour envoyer une quantité de données importante. 
    \item \textbf{Confidentialité} : La transmission des données telle quelle peut facilement être récupérée par un tiers indésirable, ce qui peut poser des problèmes dans des contextes militaire ou médical. 
\end{itemize}

\subsection{Apprentissage centralisé versus apprentissage fédéré}

Face à ces défis, deux paradigmes d'apprentissage automatique se distinguent : l'apprentissage centralisé et l'apprentissage fédéré.

Pour faire face à toutes nos données, plusieurs possibilités d'apprentissage automatique s'ouvrent. Parmi toutes les possibilités, il y a deux candidats qui tirent leur épingle du jeu : l'apprentissage centralisé et l'apprentissage fédéré.

\subsubsection{Apprentissage centralisé}

L'apprentissage centralisé est l'approche traditionnelle en apprentissage automatique. Son fonctionnement repose sur le fait que chaque capteur envoie ses données à un serveur central qui s'occupe de faire l'entraînement de manière globale. 
Cette approche a plusieurs avantages :

\begin{itemize}
    \item \textbf{Précision} : Cette approche permet d'avoir une très bonne précision 
    \item \textbf{Convergence stable} : L'apprentissage sur un ensemble de données centralisé donne des résultats plus stables au fur et à mesure de l'entraînement
\end{itemize}

Cependant, cette approche possède des désavantages, notamment liés au contexte de l'IoT :
\begin{itemize}
    \item \textbf{Condidentialié} : La transmission de toutes les données vers un serveur central expose les données à n'importe quels tiers indésirables.
    \item \textbf{Bande passante} : Le transfert de grandes quantités de données consomme énormément de bande passante réseau.
    \item \textbf{Latence élevée} : La collecte et le traitement centralisé introduisent des délais importants.
\end{itemize}

\subsubsection{Apprentissage fédéré}

L'apprentissage fédéré propose une alternative décentralisée où l'entraînement se déroule localement sur chaque capteur. Plutôt que de transmettre les données, les capteurs vont transmettre les poids qui seront agrégés sur le serveur central.
Cela présente les avantages suivants :
\begin{itemize}
    \item \textbf{Bande passante réduite} : Seuls les poids du modèle sont transmis, ce qui représente un volume de données bien inférieur aux données des capteurs.
    \item \textbf{Confidentialité} : Les données sensibles restent sur les capteurs et ne sont jamais transmises.
\end{itemize}

Néanmoins, l'apprentissage fédéré comporte aussi des inconvénients :
\begin{itemize}
    \item \textbf{Données non-IID} : L'hétérogénéité des données locales peut ralentir la convergence et réduire la performance du modèle global.
\end{itemize}

\section{Problématique et Solution Proposée}

\subsection{Le défi posé par les données non étiquetées}

Comme dit précédemment, dans le contexte de l'IoT, nous sommes dans un environnement particulièrement complexe. Les capteurs génèrent des données qui ne sont pas ou peu étiquetées, et ce dans des endroits qui peuvent être difficiles d'accès (intervention humaine difficile voire impossible), ce qui rend une labélisation manuelle délicate. 
Cette situation rend l'utilisation de l'apprentissage supervisé traditionnel impossible (cette approche nécessitant de nombreuses données labellisée).
\subsection{La solution novatrice proposée}

Pour surmonter ces obstacles, l'article propose une approche innovante qui combine trois éléments :

\begin{enumerate}
    \item \textbf{L'apprentissage fédéré} L'utilisation de l'apprentissage fédéré afin de combler les problèmes de bande passante et de confidentialité.
    
    \item \textbf{Autoencodeur} : Plutôt que d'utiliser un apprentissage supervisé classique qui nécessite des labels, l'approche repose sur des autoencodeurs capables d'apprendre des features de manière non supervisée. 
    
    \item \textbf{Agrégation décentralisée via UAV (drone)} : Un UAV se déplace de capteur en capteur pour collecter les poids des modèles locaux, les agréger, puis redistribuer le modèle global mis à jour. Cette approche est particulièrement adaptée aux capteurs dans des environnements difficiles d'accès. 
\end{enumerate}

Cette solution permet de combiner les avantages de l'apprentissage fédéré (confidentialité, efficacité de la bande passante) avec la capacité de traiter des données non étiquetées grâce aux autoencodeurs, tout en utilisant un UAV pour faciliter la communication dans des environnements difficiles.

\section{Architecture du Système et Méthodologie}

\subsection{Architecture du modèle Autoencodeur}



Le modèle proposé repose sur une architecture d'autoencodeur convolutionnel composée de trois parties principales : l'encodeur, le décodeur et le classifieur.

\bigskip

Cette arcitecture duale permet un aprentissage non supervisé de l'extraction des caractéristiques via la paire encodeur/décodeur ce qui permet de répondre au problème de données non étiquetées. En parallèle, la branche de classification permet d'évaluer la qualité des représentations apprises dans l'espace latent en les utilisant pour une tâche de classification supervisée. Cette configuration permet d'obtenir des représentations utiles pour la reconstruction tout en étant informatives pour la classification, ce qui est crucial dans un contexte où les données sont hétérogènes et non étiquetées.

\subsubsection{L'Encodeur : Extraction de features}

L'encodeur a pour fonction de transformer une image d'entrée de dimension $32 \times 32 \times 3$ (format CIFAR-10) vers un espace latent de dimension réduite. Cette compression force le modèle à apprendre les caractéristiques les plus pertinentes de l'image.

L'architecture de l'encodeur utilise une séquence de couches convolutionnelles suivies de normalisation par batch et d'activation ReLU :
\begin{itemize}
    \item \textbf{Convolution 2D} : Extrait les motifs locaux et les caractéristiques spatiales de l'image.
    \item \textbf{Batch Normalization 2D} : Normalise les activations pour stabiliser et accélérer l'entraînement.
    \item \textbf{Activation ReLU} : Introduit de la non-linéarité dans le modèle, permettant d'apprendre des représentations complexes.
\end{itemize}

L'espace latent obtenu constitue une représentation compressée et informative de l'image d'entrée, capturant les caractéristiques essentielles tout en réduisant la dimensionnalité.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.5\linewidth]{img/encodeur.png}
    \caption{Architecture de l'encodeur convolutionnel}
\end{figure}

\subsubsection{Le Décodeur : Reconstruction de l'image}

Le décodeur effectue l'opération inverse de l'encodeur : il reconstruit l'image originale $32 \times 32 \times 3$ à partir de la représentation compressée dans l'espace latent.

L'architecture du décodeur utilise également une succession de couches :
\begin{itemize}
    \item \textbf{Convolution 2D} (ou convolution transposée) : Effectue un upsampling progressif pour retrouver les dimensions spatiales originales.
    \item \textbf{Batch Normalization 2D} : Stabilise l'entraînement du décodeur.
    \item \textbf{Activation ReLU} : Maintient la non-linéarité nécessaire pour une reconstruction de qualité.
\end{itemize}

La qualité de la reconstruction est mesurée par la \textbf{Mean Squared Error (MSE)} entre l'image originale et l'image reconstruite. Cette métrique encourage le modèle à préserver l'information importante dans l'espace latent.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.5\linewidth]{img/decoder.png}
    \caption{Architecture du décodeur convolutionnel}
\end{figure}

\subsubsection{Le Classifieur : Classification à partir de l'espace latent}

En plus de la reconstruction, le modèle intègre une branche de classification qui prédit la classe de l'image à partir de sa représentation dans l'espace latent.

L'architecture du classifieur comprend :
\begin{itemize}
    \item \textbf{Flatten} : Aplatit la représentation spatiale de l'espace latent en un vecteur unidimensionnel.
    \item \textbf{Fully Connected Layer} : Couche dense qui combine les caractéristiques pour la classification.
    \item \textbf{Activation ReLU} : Non-linéarité avant la couche de sortie.
    \item \textbf{Couche de sortie} : Produit les probabilités pour les 10 classes de CIFAR-10.
\end{itemize}

Le classifieur est entraîné en utilisant la \textbf{Cross-Entropy Loss} et évalué selon la métrique d'\textbf{Accuracy} (précision de classification).

\begin{figure}[H]
    \centering
    \includegraphics[width=0.5\linewidth]{img/classifieur.png}
    \caption{Architecture du classifieur convolutionnel}
\end{figure}

\subsubsection{Fonction de perte combinée}

Dans l'article il est clair que l'entraînement du décodeur est fait avec la MSE comme loss et la validation du classiefieur avec l'accuracy mais on n'a ni information sur la loss utilisée pour le classifieur ni sur la manière dont les deux branches sont combinées. Il est de bon sens de supposer que la Cross-Entropy Loss est utilisée pour le classifieur et que les deux branches sont entraînées simultanément avec une fonction de perte combinée du type :
\[
\mathcal{L}_{\text{total}} = \alpha \cdot \mathcal{L}_{\text{reconstruction}} + \beta \cdot \mathcal{L}_{\text{classification}}
\]

Ce type de fonction de perte est cpourrament utilisée pour des optimisations multi-objectifs, où $\alpha$ et $\beta$ sont des hyperparamètres qui équilibrent l'importance relative de la reconstruction et de la classification. L'entraînement simultané permet au modèle d'apprendre des représentations dans l'espace latent qui sont à la fois utiles pour la reconstruction et discriminantes pour la classification.

\subsection{Environnement de simulation}

Pour valider l'approche proposée, un environnement de simulation a été mis en place pour reproduire de manière réaliste la communication entre les capteurs et l'UAV.

\subsubsection{Configuration de la simulation}

L'environnement de simulation présente les caractéristiques suivantes :
\begin{itemize}
    \item \textbf{Grille spatiale} : Une zone de $300 \times 300$ unités représentant l'environnement de déploiement. (\textit{Le papier dit $200 \times 200$ mais cela semble être une coquille car ce n'est pas compatible avec les position des capteurs données par la suite})
    \item \textbf{4 capteurs} : Positionnés à différents emplacements dans la grille, chacun disposant d'un dataset local.
    \item \textbf{1 UAV} : Un drone qui se déplace dans l'environnement pour collecter et distribuer les modèles.
    \item \textbf{Framework GrADyS-SIM NG} : Un framework de simulation spécialisé pour les systèmes de drones et de capteurs au sol.
\end{itemize}

\bigskip

Le protocole de communication simulé comprend plusieurs étapes :
\begin{enumerate}
    \item L'UAV démarre depuis une position initiale et planifie sa trajectoire pour visiter tous les capteurs.
    \item À chaque visite, l'UAV se connecte au capteur, récupère ses poids de modèle mis à jour.
    \item Après avoir collecté les poids de tous les capteurs disponibles, l'UAV effectue l'agrégation.
    \item L'UAV redistribue ensuite le modèle global mis à jour à chaque capteur lors d'une seconde tournée.
\end{enumerate}

Cette simulation permet d'évaluer non seulement la performance du modèle, mais aussi l'efficacité du protocole de communication dans un scénario réaliste, en simulant les contraintes de bande passante et de latence typiques des environnements réels.

\begin{figure}[H]
    \centering
    \begin{subfigure}[b]{0.45\textwidth}
        \centering
        \includegraphics[width=\textwidth]{img/drone1.png}
        \caption{Collecte auprès du capteur 1}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.45\textwidth}
        \centering
        \includegraphics[width=\textwidth]{img/drone2.png}
        \caption{Collecte auprès du capteur 2}
    \end{subfigure}
    
    \vspace{0.5cm}
    
    \begin{subfigure}[b]{0.45\textwidth}
        \centering
        \includegraphics[width=\textwidth]{img/drone3.png}
        \caption{Collecte auprès du capteur 3}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.45\textwidth}
        \centering
        \includegraphics[width=\textwidth]{img/drone4.png}
        \caption{Collecte auprès du capteur 4}
    \end{subfigure}
    \caption{Parcours de l'UAV pour la collecte des modèles locaux}
    \label{fig:uav-collecte}
\end{figure}

\subsubsection{Répartition des données CIFAR-10}

Le dataset CIFAR-10 est utilisé pour l'expérimentation. Il contient :
\begin{itemize}
    \item 60 000 images en couleur de dimension $32 \times 32 \times 3$
    \item 10 classes différentes (avion, automobile, oiseau, chat, cerf, chien, grenouille, cheval, bateau, camion)
    \item 6 000 images par classe
\end{itemize}

Pour simuler un scénario réaliste de données \textbf{non-IID}, le dataset est réparti de manière hétérogène entre les 4 capteurs. Chaque capteur reçoit une distribution déséquilibrée des classes, ce qui signifie qu'un capteur peut avoir beaucoup d'exemples de certaines classes et très peu d'autres. Cette répartition non uniforme reflète les conditions réelles où chaque capteur observe des phénomènes différents selon son emplacement.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{img/repartition.png}
    \caption{Répartition non-IID des données entre les capteurs}
\end{figure}

\subsection{Modèle de fusion et agrégation}

\subsubsection{Processus d'entraînement et d'agrégation}

Le processus d'apprentissage fédéré suit un cycle itératif comprenant les étapes suivantes :

\begin{enumerate}
    \item \textbf{Entraînement local} : Chaque capteur entraîne son modèle local sur son dataset pendant $N$ epochs. Durant cette phase, le capteur optimise les poids de son autoencodeur en utilisant la fonction de perte combinée.
    
    \item \textbf{Requête de communication} : Après $N$ epochs d'entraînement local, le capteur stoppe la mise à jour de son modèle et entre en mode attente, signalant qu'il est prêt à communiquer avec l'UAV.
    
    \item \textbf{Transmission des poids locaux} : Lorsque l'UAV arrive à proximité, le capteur transmet une version compressée de ses poids au drone. Cette compression est essentielle pour réduire le temps et l'énergie nécessaires à la transmission.
    
    \item \textbf{Agrégation des modèles locaux} : L'UAV collecte les poids de tous les capteurs qui ont communiqué avec lui, puis calcule la moyenne pondérée de ces poids. Cette agrégation suit l'algorithme \textbf{FedAvg} (Federated Averaging), qui calcule une moyenne des paramètres des modèles locaux. (\textit{L'article ne mentionne pas explicitant la méthode de fusion, on sait juste qu'il fait la moyenne des poids, FedAvg est une méthode classique en federated learning})
    
    \item \textbf{Distribution des poids globaux} : Une fois l'agrégation effectuée, l'UAV redistribue le nouveau modèle global à tous les capteurs.
    
    \item \textbf{Mise à jour et reprise de l'entraînement} : Chaque capteur met à jour son modèle local avec les nouveaux poids globaux, puis reprend l'entraînement local pour une nouvelle itération.
\end{enumerate}

\subsubsection{Fusion itérative pour combattre la non-IID}

L'approche utilise une \textbf{fusion itérative} basée sur l'algorithme FedAvg. Ce processus itératif est crucial pour surmonter les défis posés par la distribution non-IID des données :
\begin{itemize}
    \item À chaque itération, l'agrégation permet de combiner les connaissances apprises localement par chaque capteur.
    \item Les poids globaux redistribués incorporent des informations de toutes les distributions locales, ce qui aide chaque capteur à généraliser au-delà de ses données locales biaisées.
    \item Au fil des itérations, le modèle global converge vers une solution qui performe bien sur l'ensemble des distributions, malgré l'hétérogénéité initiale.
\end{itemize}

\bigskip

Ainsi le modèles global qui emergera sera redistribué à tous les capteur et aura appris sur toutes les classes présente dans le dataset original.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.6\textwidth]{img/tr6.png}
    \caption{Fusion des données au sein de l'UAV}
\end{figure}

\subsubsection{Optimisation des communications}

La réduction de la bande passante est un objectif majeur du système. Pour cela, plusieurs techniques sont mises en œuvre :

\begin{enumerate}
    \item \textbf{Entraînement avec Quantization-Aware Training (QAT)} : Le modèle est entraîné en tenant compte de la quantification future, ce qui améliore sa robustesse à la perte de précision.
    
    \item \textbf{Quantification des poids} : Les poids du modèle sont quantifiés (typiquement de float32 à int8), ce qui réduit la taille des données de \textbf{75\%}.
    
    \item \textbf{Compression avec gzip} : Après quantification, les poids sont compressés avec un algorithme de compression sans perte (gzip) pour réduire davantage la taille de transmission.
    
    \item \textbf{Décompression} : À la réception, l'UAV ou le capteur décompresse les données de manière lossless, récupérant exactement les poids quantifiés.
    
    \item \textbf{Agrégation} : L'UAV agrège les poids décompressés selon l'algorithme FedAvg.
    
    \item \textbf{Distribution} : Les poids globaux sont à nouveau compressés pour la redistribution vers les capteurs.
    
    \item \textbf{Mise à jour locale} : Chaque capteur décompresse et charge les nouveaux poids dans son modèle.
\end{enumerate}

Cette chaîne d'optimisation permet de réduire significativement le volume de données échangées, ce qui est crucial pour minimiser la consommation énergétique et le temps de communication dans un contexte IoT à ressources limitées. Néanmoins cette compression à un coût qui impactera la précision du modèle, d'où le compromis à trouver entre efficacité de communication et performance du modèle.

\section{Résultats Expérimentaux}

Les expérimentations ont été effectuées sur deux scénarios différents. Le premier scénario est avec un modèle supervisé classique afin d'avoir une base de comparaison. Le deuxième scénario est via le modèle développé dans l'article.

\subsection{Analyse des matrices de confusion}

Les matrices de confusion fournissent une visualisation détaillée des performances de classification pour chaque classe du dataset CIFAR-10.

\subsubsection{Modèle supervisé}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.6\textwidth]{img/confusion_supervise.png}
    \caption{Matrice de confusion pour le modèle supervisé}
\end{figure}

La matrice de confusion sur le modèle supervisé montre que
\begin{itemize}
    \item \textbf{Classes mieux séparées} : Les prédictions sont concentrées sur le diagonal de la matrice, ce qui montre que les classes sont bien distinguées les unes des autres.
    \item \textbf{Moins d'erreurs de classification} : Le nombre de faux positifs et faux négatifs est relativement faible.
\end{itemize}

\subsubsection{Autoencodeur avec classification}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.6\textwidth]{img/confusion_autoencoder.png}
    \caption{Matrice de confusion pour le modèle avec l'autoencodeur}
\end{figure}

Le modèle basé sur l'autoencodeur montre des résultats différents :
\begin{itemize}
    \item \textbf{Confusion accrue entre certaines classes} : La matrice présente plus d'éléments hors diagonale, indiquant des erreurs de classification plus fréquentes.
    \item \textbf{Prédictions moins confiantes} : Les probabilités sont moins affirmées, reflétant une incertitude plus élevée.
    \item \textbf{Accuracy réduite} : La précision globale est inférieure à celle du modèle supervisé.
    \item \textbf{Compromis reconstruction/classification} : Le modèle doit équilibrer deux objectifs, ce qui peut limiter sa performance pure en classification.
\end{itemize}

\subsubsection{Interprétation}

La comparaison montre clairement que le modèle supervisé offre une meilleure précision de classification, ce qui est attendu puisqu'il est directement optimisé pour cette tâche avec des labels disponibles. Cependant, l'autoencodeur, malgré une précision moins bonne, reste une solution viable dans le contextes IoT où les labels ne sont pas disponibles. 

\subsection{Analyse t-SNE des représentations}

\subsubsection{Modèle supervisé}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.6\textwidth]{img/tsne_supervise.png}
    \caption{T-SNE du modèle supervisé}
\end{figure}

La visualisation t-SNE du modèle supervisé révèle :
\begin{itemize}
    \item \textbf{Clusters bien séparés} : Les points correspondant à chaque classe forment des groupes distincts et compacts.
    \item \textbf{Frontières nettes entre classes} : De manière générale, on distingue assez bien les frontières des différentes classes. 
\end{itemize}

\subsubsection{Autoencodeur}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.6\textwidth]{img/tsne_autoencoder.png}
    \caption{T-SNE du modèle avec l'autoencodeur}
\end{figure}

Pour l'autoencodeur, la visualisation t-SNE montre :
\begin{itemize}
    \item \textbf{Clusters plus diffus} : Les groupes de classes sont moins compacts et présentent plus de dispersion.
    \item \textbf{Représentations plus générales} : On repère moins les frontières entre les différentes classes. 
\end{itemize}

\subsubsection{Implications}

L’analyse t-SNE montre clairement que le modèle supervisé apprend des features très discriminantes, donc parfaites pour la classification. À l’inverse, l’autoencodeur apprend des représentations plus générales, centrées sur la reconstruction de l’image. Elles sont donc moins optimisées pour de la classification pure, mais l’avantage c’est qu’elles sont apprises sans supervision. Du coup, elles ont potentiellement une meilleure robustesse quand la distribution des données change, ce qui est particulièrement intéressant dans des environnements IoT hétérogènes.

\section{Conclusion}

\subsection{Les compromis clés de l'approche}

L'article présente une approche innovante qui intègre plusieurs techniques pour surmonter les défis de l'apprentissage automatique dans les réseaux IoT. Trois compromis principaux émergent de cette étude :

\subsubsection{Quantification des poids vs. précision}

La \textbf{quantification des poids du modèle} permet une réduction significative de la bande passante nécessaire pour la communication. En convertissant les poids de float32 à int8, le volume de données est réduit de 75\%, ce qui améliore considérablement l'efficacité énergétique et la rapidité des échanges. Toutefois, cette compression s'accompagne d'une légère perte de précision numérique, bien que l'utilisation du Quantization-Aware Training permette de limiter l'impact sur les performances du modèle mais l'article ne décrit pas exactement comment cette technique est implémentée.

\subsubsection{Données non-IID vs. réalisme}

La \textbf{répartition non-IID des données} entre les capteurs rend la simulation beaucoup plus réaliste, reflétant les conditions réelles où chaque capteur observe des distributions différentes. Cependant, cette hétérogénéité complique la convergence du modèle global et peut réduire les performances par rapport à un scénario idéalisé avec des données uniformément distribuées. L'utilisation de la fusion itérative (FedAvg) permet de partiellement atténuer cet effet.

\subsubsection{Autoencodeurs vs. accuracy de classification}

L'utilisation d'\textbf{autoencodeurs pour l'extraction de features non supervisée} permet au système de fonctionner sans labels, ce qui est essentiel dans les environnements IoT où l'annotation est impossible. Néanmoins, ce choix entraîne une \textbf{accuracy de classification inférieure} comparée à un modèle supervisé classique. Ce compromis est acceptable dans le contexte où la supervision n'est tout simplement pas disponible.

\subsection{La fusion et l'agrégation distribuée}

L'approche proposée combine plusieurs innovations pour créer un système complet et cohérent :

\begin{itemize}
    \item \textbf{Entraînement local optimisé} : Chaque capteur effectue l'apprentissage localement, ce qui respecte les ressources limitées en termes de puissance de calcul et d'énergie.
    
    \item \textbf{Transmission uniquement des poids} : Plutôt que de transmettre les données brutes (potentiellement sensibles et volumineuses), seuls les paramètres du modèle sont échangés, préservant ainsi la vie privée tout en réduisant la bande passante.
    
    \item \textbf{Agrégation itérative pour combattre la non-IID} : Le processus de fusion répété permet au modèle global de progressivement intégrer les spécificités de toutes les distributions locales, produisant un modèle qui est globalement plus robuste et performant que n'importe quel modèle local isolé.
\end{itemize}

\bigskip 

Ce dernier point est particulièrement important : bien que chaque modèle local soit limité par son dataset restreint et biaisé, le modèle global agrégé bénéficie de la diversité des données collectées par tous les capteurs. Ainsi, le modèle global surpasse les modèles locaux en termes de généralisation et de robustesse. (\textit{Même si il n'y a pas de comparaison explicite on doit faire confiance aux auteurs})

\subsection{Perspectives et contributions de l'article}

L'article présente plusieurs contributions importantes :

\begin{itemize}
    \item \textbf{Première implémentation de cette approche} : La combinaison d'apprentissage fédéré, d'autoencodeurs et d'agrégation par UAV dans un contexte IoT constitue une approche novatrice.
    
    \item \textbf{Utilisation d'UAV pour la collecte} : L'introduction d'un drone comme médiateur de communication ouvre une nouvelle dimension pour la collecte décentralisée de données dans des environnements où l'infrastructure réseau traditionnelle est absente ou limitée.
    
    \item \textbf{Extension possible à d'autres types de données} : Bien que l'article se concentre sur la classification d'images CIFAR-10, la méthodologie pourrait être étendue à des applications plus réalistes telles que la surveillance environnementale, l'agriculture de précision, ou la surveillance industrielle.
\end{itemize}

\subsection{Limites et critiques}

Malgré ses contributions, l'article présente certaines limites :

\begin{itemize}
    \item \textbf{Focus excessif sur la transmission} : L'article met beaucoup l'accent sur l'optimisation de la communication (quantification, compression), mais moins sur l'amélioration de la qualité du modèle lui-même.
    
    \item \textbf{Fusion très simple} : L'agrégation par moyenne pondérée (FedAvg) ne prend pas en compte la qualité ou la fiabilité des modèles locaux. Des approches plus sophistiquées pourraient pondérer différemment les contributions selon la performance locale ou la quantité de données disponibles.
    
    \item \textbf{Manque de précision et erreurs} : L'article contient plusieurs imprécisions dans les descriptions des méthodes et des résultats, ce qui rend difficile la réplication exacte de l'expérience. Certains détails techniques importants sont omis ou peu clairs mais des recherches externe peuvent permettre de déduire les choix faits par les auteurs en se basant sur les approches classiques.
\end{itemize}

\subsection{Verdict final}

L'article constitue un \textbf{bon Proof of Concept (POC)} qui démontre la faisabilité de combiner apprentissage fédéré, autoencodeurs et communication par UAV dans un contexte IoT. L'approche proposée offre une solution viable pour des scénarios où les données sont distribuées, non étiquetées et où la confidentialité et l'efficacité énergétique sont primordiales.

Cependant, l'article n'est \textbf{pas suffisamment détaillé pour être pleinement réplicable}. Des informations supplémentaires sur l'architecture exacte des modèles, les hyperparamètres utilisés, et les protocoles de communication seraient nécessaires pour permettre une reproduction fidèle des résultats.

En conclusion, cette recherche ouvre des perspectives intéressantes pour l'apprentissage automatique distribué dans les réseaux IoT, mais nécessiterait des développements supplémentaires et une documentation plus rigoureuse pour être applicable dans des déploiements réels à grande échelle.

\end{document}
